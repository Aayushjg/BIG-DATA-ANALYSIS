# BIG-DATA-ANALYSIS

*COMPANY*: CODTECH IT SOLUTIONS

*NAME* : AAYUSH JANGID

*INTERN ID* : CT08DG1246

*DOMAIN* : DATA ANALYSIS

*DURATION* : 8 WEEKS

*MENTOR* : NEELA SANTOSH

**For Task 1 of the data analysis internship, I performed big data analysis using PySpark on a large-scale dataset simulating New York City Yellow Taxi Trips. The dataset contained over 100,000 records with details such as pickup and drop-off timestamps, passenger count, trip distance, fare amount, and total amount paid. Using PySpark, a distributed computing framework built on Apache Spark, I was able to load, clean, and analyze this data efficiently. The process began with removing rows containing null values in critical columns to ensure data quality. I then conducted various aggregations, such as calculating the total number of trips, analyzing passenger count distribution, and computing average trip distances per group size. Additionally, I extracted the pickup hour from timestamps to identify peak ride times, which revealed that most trips occurred during morning and evening rush hours. These insights are valuable for understanding urban mobility patterns and can support decision-making in areas like pricing strategy and fleet management. The use of PySpark demonstrated how large datasets can be processed with scalability and speed, laying a strong foundation for more complex data engineering tasks. This task enhanced my skills in big data handling, transformation, and deriving meaningful business insights through distributed processing.**


*OUTPUT*:
![Image](https://github.com/user-attachments/assets/36acd0ea-e2f3-4802-bcf7-5bc80afd136f)
![Image](https://github.com/user-attachments/assets/16fff9eb-34ac-4cf9-bfd4-ab2dc08310f1)
